{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XRT_TPU_CONFIG']='tpu_worker;0;10.77.227.146:8470'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "RESULT_IMG_PATH = '/tmp/test_result.png'\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "def plot_results(images):\n",
    "  #inv_norm = transforms.Normalize((-0.1307/0.3081,), (1/0.3081,))\n",
    "\n",
    "  num_images = images.shape[0]\n",
    "  fig, axes = plt.subplots(4, 6, figsize=(11, 9))\n",
    "\n",
    "  for i, ax in enumerate(fig.axes):\n",
    "    ax.axis('off')\n",
    "    if i >= num_images:\n",
    "      continue\n",
    "    img = images[i]\n",
    "    #img = inv_norm(img)\n",
    "    img = img.squeeze() # [1,Y,X] -> [Y,X]    \n",
    "    ax.imshow(img)\n",
    "  plt.savefig(RESULT_IMG_PATH, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "FLAGS = {}\n",
    "FLAGS['datadir'] = \"/tmp/mnist\"\n",
    "FLAGS['batch_size'] = 64\n",
    "FLAGS['num_workers'] = 4\n",
    "FLAGS['learning_rate'] = 0.001\n",
    "FLAGS['momentum'] = 0.5\n",
    "FLAGS['num_epochs'] = 100\n",
    "FLAGS['num_cores'] = 8\n",
    "FLAGS['log_steps'] = 20\n",
    "FLAGS['metrics_debug'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_data():\n",
    "    compose = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "    out_dir = '{}/dataset'.format(FLAGS['datadir'])\n",
    "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminativeNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DiscriminativeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, out_channels=128, kernel_size=4, \n",
    "                stride=2, padding=1, bias=False\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=128, out_channels=256, kernel_size=4,\n",
    "                stride=2, padding=1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=256, out_channels=512, kernel_size=4,\n",
    "                stride=2, padding=1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=512, out_channels=1024, kernel_size=4,\n",
    "                stride=2, padding=1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # Flatten and apply sigmoid\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GenerativeNet, self).__init__()\n",
    "        \n",
    "        self.linear = torch.nn.Linear(100, 1024*4*4)\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=1024, out_channels=512, kernel_size=4,\n",
    "                stride=2, padding=1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=512, out_channels=256, kernel_size=4,\n",
    "                stride=2, padding=1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=256, out_channels=128, kernel_size=4,\n",
    "                stride=2, padding=1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=128, out_channels=1, kernel_size=4,\n",
    "                stride=2, padding=1, bias=False\n",
    "            )\n",
    "        )\n",
    "        self.out = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project and reshape\n",
    "        print(\"Input\",x.size())\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = x.view(x.shape[0], 1024, 4, 4)\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # Apply Tanh\n",
    "        print(\"Output\",x.size())\n",
    "        return self.out(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(0.00, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_target(size, device):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data.to(device)\n",
    "\n",
    "def fake_data_target(size, device):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise\n",
    "def noise(size, device):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    return n.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input torch.Size([64, 100])\n",
      "Output torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1]) torch.Size([64, 1])\n",
      "Input torch.Size([64, 100])\n",
      "Output torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([1024, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1]) torch.Size([64, 1])\n",
      "Input torch.Size([64, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in device=TPU:0: Target and input must have the same number of elements. target nelement (64) != input nelement (1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output torch.Size([64, 1, 64, 64])\n",
      "torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([1024, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 119, in _start_fn\n",
      "    fn(gindex, *args)\n",
      "Exception in device=TPU:7: Target and input must have the same number of elements. target nelement (64) != input nelement (1024)\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 120, in _mp_fn\n",
      "    train_gan(rank)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 109, in train_gan\n",
      "    d_error, g_error = train_loop_fn (para_loader.per_device_loader(device))\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 119, in _start_fn\n",
      "    fn(gindex, *args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1]) torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-63-67079464aba3>\", line 96, in train_loop_fn\n",
      "    real_data, fake_data, device)\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 120, in _mp_fn\n",
      "    train_gan(rank)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-63-67079464aba3>\", line 65, in train_step_discriminator\n",
      "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0), device))\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 109, in train_gan\n",
      "    d_error, g_error = train_loop_fn (para_loader.per_device_loader(device))\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 558, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([1024, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "Exception in device=TPU:4: Target and input must have the same number of elements. target nelement (64) != input nelement (1024)\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 520, in forward\n",
      "    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 96, in train_loop_fn\n",
      "    real_data, fake_data, device)\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 2408, in binary_cross_entropy\n",
      "    \"!= input nelement ({})\".format(target.numel(), input.numel()))\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 65, in train_step_discriminator\n",
      "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0), device))\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 558, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "ValueError: Target and input must have the same number of elements. target nelement (64) != input nelement (1024)\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 119, in _start_fn\n",
      "    fn(gindex, *args)\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 520, in forward\n",
      "    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 2408, in binary_cross_entropy\n",
      "    \"!= input nelement ({})\".format(target.numel(), input.numel()))\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 120, in _mp_fn\n",
      "    train_gan(rank)\n",
      "ValueError: Target and input must have the same number of elements. target nelement (64) != input nelement (1024)\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 109, in train_gan\n",
      "    d_error, g_error = train_loop_fn (para_loader.per_device_loader(device))\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 96, in train_loop_fn\n",
      "    real_data, fake_data, device)\n",
      "  File \"<ipython-input-63-67079464aba3>\", line 65, in train_step_discriminator\n",
      "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0), device))\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 558, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 520, in forward\n",
      "    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "  File \"/home/sivaibhav/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\", line 2408, in binary_cross_entropy\n",
      "    \"!= input nelement ({})\".format(target.numel(), input.numel()))\n",
      "ValueError: Target and input must have the same number of elements. target nelement (64) != input nelement (1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input torch.Size([64, 100])\n",
      "Output torch.Size([64, 1, 64, 64])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1]) torch.Size([64, 1])\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "process 0 terminated with exit code 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-67079464aba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n\u001b[0;32m--> 126\u001b[0;31m           start_method='fork')\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         start_method=start_method)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise Exception(\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: process 0 terminated with exit code 17"
     ]
    }
   ],
   "source": [
    "def train_gan(rank):\n",
    "    torch.manual_seed(1)\n",
    "    \n",
    "    if not xm.is_master_ordinal():\n",
    "        # Barrier: Wait until master is done downloading\n",
    "        xm.rendezvous('download_only_once')\n",
    "    # Dataset\n",
    "    data = mnist_data()\n",
    "    if xm.is_master_ordinal():\n",
    "        # Master is done, other workers can proceed now\n",
    "        xm.rendezvous('download_only_once')\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        data,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True)\n",
    "    \n",
    "\n",
    "    # Create loader with data, so that we can iterate over it\n",
    "    #train_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "      data,\n",
    "      batch_size=FLAGS['batch_size'],\n",
    "      sampler=train_sampler,\n",
    "      num_workers=FLAGS['num_workers'],\n",
    "      drop_last=True)\n",
    "\n",
    "    # Num batches\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    device = xm.xla_device()\n",
    "    \n",
    "    generator = GenerativeNet().to(device)\n",
    "    #generator.apply(init_weights)\n",
    "\n",
    "    discriminator = DiscriminativeNet().to(device)\n",
    "    #discriminator.apply(init_weights)\n",
    "    \n",
    "    # Optimizers\n",
    "    d_optimizer = Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    g_optimizer = Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "    # Number of epochs\n",
    "    num_epochs = FLAGS['num_epochs'] \n",
    "    # Loss function\n",
    "    loss = nn.BCELoss()\n",
    "    \n",
    "    num_test_samples = 16\n",
    "    test_noise = noise(num_test_samples, device)\n",
    "    \n",
    "    def train_step_discriminator(optimizer, real_data, fake_data, device):\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1. Train on Real Data\n",
    "        prediction_real = discriminator(real_data)\n",
    "        # Calculate error and backpropagate\n",
    "        error_real = loss(prediction_real, real_data_target(real_data.size(0), device))\n",
    "        error_real.backward()\n",
    "\n",
    "        # 2. Train on Fake Data\n",
    "        prediction_fake = discriminator(fake_data)\n",
    "        # Calculate error and backpropagate\n",
    "        error_fake = loss(prediction_fake, fake_data_target(real_data.size(0), device))\n",
    "        error_fake.backward()\n",
    "\n",
    "        # Update weights with gradients\n",
    "        xm.optimizer_step(optimizer)\n",
    "\n",
    "        return error_real + error_fake, prediction_real, prediction_fake\n",
    "        #return (0, 0, 0)\n",
    "\n",
    "    def train_step_generator(optimizer, fake_data, device):\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Sample noise and generate fake data\n",
    "        prediction = discriminator(fake_data)\n",
    "        # Calculate error and backpropagate\n",
    "        error = loss(prediction, real_data_target(prediction.size(0), device))\n",
    "        error.backward()\n",
    "        # Update weights with gradients\n",
    "        xm.optimizer_step(optimizer)\n",
    "\n",
    "        # Return error\n",
    "        return error\n",
    "\n",
    "\n",
    "    def train_loop_fn(loader):\n",
    "        tracker = xm.RateTracker()\n",
    "        for n_batch, (real_batch,_) in enumerate(loader):\n",
    "            # Train Step Descriminator\n",
    "            real_data = Variable(real_batch).to(device)\n",
    "            fake_data = generator(noise(real_data.size(0), device)).detach()\n",
    "            d_error, d_pred_real, d_pred_fake = train_step_discriminator(d_optimizer,\n",
    "                                                                real_data, fake_data, device)\n",
    "            #Train Step Generator\n",
    "            fake_data = generator(noise(real_batch.size(0), device))\n",
    "            g_error = train_step_generator(g_optimizer, fake_data, device)\n",
    "        print(f'D_ERROR: {d_error}, G_ERROR: {g_error}')\n",
    "        return d_error, g_error\n",
    "\n",
    "\n",
    "            # Display Test Images\n",
    "            # Save Model Checkpoints\n",
    "\n",
    "    for epoch in range(1, FLAGS['num_epochs'] +1):\n",
    "        para_loader = pl.ParallelLoader(train_loader, [device])\n",
    "        d_error, g_error = train_loop_fn (para_loader.per_device_loader(device))\n",
    "        xm.master_print(\"Finished training epoch {}: D_error:{}, G_error\".format(epoch, d_error, g_error))\n",
    "        if rank == 0 :\n",
    "            # Retrieve tensors that are on TPU core 0 and plot.\n",
    "            plot_results(vectors_to_images(generator(test_noise).detach()).cpu())\n",
    "\n",
    "# Start training processes\n",
    "def _mp_fn(rank, flags):\n",
    "    global FLAGS\n",
    "    FLAGS = flags\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    train_gan(rank)\n",
    "    #if rank == 0:\n",
    "      # Retrieve tensors that are on TPU core 0 and plot.\n",
    "      # plot_results(images.cpu())\n",
    "\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
    "          start_method='fork')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=RESULT_IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
